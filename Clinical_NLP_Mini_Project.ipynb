{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical NLP Mini-Project:Structuring Unstructured Paediatric Records"
      ],
      "metadata": {
        "id": "zSbIR_uATuwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### This project demonstrates a compact natural language processing (NLP) pipeline for transforming unstructured clinical text into structured, AI-ready data. The focus is on Clinical Named Entity Recognition (CNER) as a foundational step in clinical data digitisation.\n",
        "\n",
        "###### The notebook presents a proof-of-concept workflow that prioritises clarity, reproducibility, and methodological correctness rather than model training or large-scale evaluation."
      ],
      "metadata": {
        "id": "u3xUqad-T5hH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Workflow Overview\n",
        "\n",
        "1. Load a public, de-identified clinical text dataset.\n",
        "2. Apply minimal preprocessing to preserve clinical meaning.\n",
        "3. Perform Clinical Named Entity Recognition using a pre-trained transformer model.\n",
        "4. Post-process and structure extracted entities into tabular form.\n",
        "5. Demonstrate a short human-in-the-loop review step.\n",
        "6. Discuss ethical considerations, limitations, and future extensions."
      ],
      "metadata": {
        "id": "bmLdHSbtWmmX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ2TjvC9S-w1"
      },
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# NLP / Transformer utilities\n",
        "from transformers import pipeline\n",
        "\n",
        "print(\"Environment initialised and libraries loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MTSamples dataset (downloaded from Kaggle)\n",
        "df = pd.read_csv(\"/content/mtsamples.csv\")\n",
        "\n",
        "# Drop records without clinical text\n",
        "df = df.dropna(subset=[\"transcription\"]).reset_index(drop=True)\n",
        "\n",
        "# Inspect the dataset\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "hVp4_Y8nZ4Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter for paediatric-related notes\n",
        "df_peds = df[df[\"medical_specialty\"].str.contains(\"Pediatrics\", na=False)].reset_index(drop=True)\n",
        "\n",
        "print(f\"Total notes: {len(df)}\")\n",
        "print(f\"Paediatric-related notes: {len(df_peds)}\")\n"
      ],
      "metadata": {
        "id": "NqE8YAKzaJ9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Minimal Preprocessing\n",
        "\n",
        "Clinical text contains important cues such as negation (e.g., “no fever”), abbreviations, and shorthand. This step applies only light, safe preprocessing:\n",
        "- standardise whitespace\n"
      ],
      "metadata": {
        "id": "8EAlQmg3bl84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_whitespace(text: str) -> str:\n",
        "    text = str(text)\n",
        "    text = text.replace(\"\\r\", \"\\n\")\n",
        "    text = re.sub(r\"\\n{2,}\", \"\\n\\n\", text)      # to collapse newlines\n",
        "    text = re.sub(r\"[ \\t]+\", \" \", text)         # to collapse spaces or tabs\n",
        "    return text.strip()\n",
        "\n",
        "df_peds[\"text_raw\"] = df_peds[\"transcription\"].astype(str)\n",
        "df_peds[\"text\"] = df_peds[\"text_raw\"].apply(clean_whitespace)\n",
        "\n",
        "df_peds[[\"sample_name\", \"medical_specialty\", \"text\"]].head(3)"
      ],
      "metadata": {
        "id": "NW5U62VWaZLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinical Named Entity Recognition (CNER)\n",
        "\n",
        "The goal is to convert unstructured clinical text into structured signals by extracting key clinical concepts using a pre-trained clinical transformer encoder (DistilBERT-based, i2b2-trained) for token-level named entity recognition:\n",
        "- PROBLEM (conditions, symptoms)\n",
        "- TEST (labs, imaging, examinations)\n",
        "- TREATMENT (medications, procedures)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Enpoqz81jRK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner = pipeline(\n",
        "    \"token-classification\",\n",
        "    model=\"nlpie/clinical-distilbert-i2b2-2010\",\n",
        "    aggregation_strategy=\"max\"\n",
        ")\n",
        "\n",
        "# Quick test\n",
        "sample_text = df_peds.loc[0, \"text\"]\n",
        "ents = ner(sample_text)\n",
        "\n",
        "ents[:10], len(ents)\n"
      ],
      "metadata": {
        "id": "PWZNUBBQmVbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_MAP = {\"problem\":\"PROBLEM\", \"test\":\"TEST\", \"treatment\":\"TREATMENT\"}\n"
      ],
      "metadata": {
        "id": "vN-VENe_p1Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structuring Extracted Clinical Entities\n",
        "\n",
        "The output of the CNER model consists of entity mentions identified within free-text clinical notes. To enable downstream analysis and reuse, these outputs are converted into structured tabular formats.\n",
        "\n",
        "Two representations are created:\n",
        "- a long format table, where each row corresponds to a single extracted entity, and\n",
        "- a wide format table, where entities are grouped by note and clinical category."
      ],
      "metadata": {
        "id": "na2qcwPEq7zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = min(100, len(df_peds))  # start with 100 notes\n",
        "\n",
        "rows = []\n",
        "for i in range(N):\n",
        "    note_id = int(df_peds.index[i])\n",
        "    text = df_peds.loc[note_id, \"text\"]\n",
        "    ents = ner(text)\n",
        "\n",
        "    for e in ents:\n",
        "        rows.append({\n",
        "            \"note_id\": note_id,\n",
        "            \"sample_name\": df_peds.loc[note_id, \"sample_name\"],\n",
        "            \"medical_specialty\": df_peds.loc[note_id, \"medical_specialty\"],\n",
        "            \"entity_text\": e[\"word\"],\n",
        "            \"label\": LABEL_MAP.get(e[\"entity_group\"], e[\"entity_group\"].upper()),\n",
        "            \"start\": e[\"start\"],\n",
        "            \"end\": e[\"end\"],\n",
        "            \"score\": float(e[\"score\"]),\n",
        "        })\n",
        "\n",
        "entities_long = pd.DataFrame(rows)\n",
        "entities_long.to_csv(\"entities_long.csv\", index=False)\n",
        "\n",
        "entities_long.head(), entities_long[\"label\"].value_counts()\n"
      ],
      "metadata": {
        "id": "IhLa9tYLqggu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entities_wide = (\n",
        "    entities_long.groupby([\"note_id\",\"label\"])[\"entity_text\"]\n",
        "    .apply(lambda s: sorted(set(s)))\n",
        "    .unstack(fill_value=[])\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "entities_wide.to_csv(\"entities_wide.csv\", index=False)\n",
        "entities_wide.head()\n"
      ],
      "metadata": {
        "id": "zn0aArerrLvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Human-in-the-Loop (HITL) Review\n",
        "\n",
        "Automated clinical NLP systems can produce errors, particularly in complex or safety-critical contexts. To illustrate how human expertise can guide and validate model outputs, a human-in-the-loop (HITL) review step is included(for just 20 samples) to manually identify incorrect or missing entities, correct misclassified labels, and document common error patterns."
      ],
      "metadata": {
        "id": "2IK27nNPoZK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample a small number of entities for HITL review\n",
        "hitl_sample = (\n",
        "    entities_long\n",
        "    .sample(n=20, random_state=42)\n",
        "    .assign(\n",
        "        corrected_label=\"\",\n",
        "        error_type=\"\",\n",
        "        review_notes=\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Save HITL review log as a csv file\n",
        "hitl_sample.to_csv(\"hitl_review_log.csv\", index=False)\n",
        "\n",
        "hitl_sample\n"
      ],
      "metadata": {
        "id": "qA6Djzfrsscb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The HITL review table is exported as a template; annotation fields are intended to be completed by a clinician or qualified domain expert.\n"
      ],
      "metadata": {
        "id": "g3gIsnbYrnXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ethics, Limitations, and Next Steps\n",
        "\n",
        "### Ethical Considerations\n",
        "This project uses a public, de-identified clinical text dataset to avoid exposure to identifiable patient information. No attempt is made to re-identify individuals or infer sensitive attributes. In real clinical deployments, strict data governance, institutional approvals, and clinician oversight would be required.\n",
        "\n",
        "### Limitations\n",
        "The dataset used here is limited in size and not specific to a single healthcare system. The NER model is applied without fine-tuning, which can result in label ambiguity or spurious extractions. As demonstrated, automated outputs should not be treated as clinically authoritative without expert review.\n",
        "\n",
        "### Next Steps\n",
        "Future extensions could include applying the pipeline to institution-specific clinical records under appropriate governance, incorporating optical character recognition (OCR) for handwritten notes, expanding domain-specific vocabularies, and using expert feedback to iteratively improve extraction quality.\n"
      ],
      "metadata": {
        "id": "RaoQ2CZ2sjQh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "znNEjag9px1S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}